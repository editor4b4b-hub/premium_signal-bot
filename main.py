from dotenv import load_dotenv
load_dotenv()

import os
import json
import time
import logging
import requests
import random
import asyncio
import openai
from datetime import datetime
from telegram import Update
from telegram.ext import (
    ApplicationBuilder,
    CommandHandler,
    MessageHandler,
    filters,
    ContextTypes,
)

# CONFIG: environment variables
BOT_TOKEN = os.getenv("BOT_TOKEN")
OPENAI_API_KEY = os.getenv("Premium_Signal")  # optional

# OpenAI client (new sdk style). If OPENAI_API_KEY not provided, client remains None.
client = None
if OPENAI_API_KEY:
    openai.api_key = OPENAI_API_KEY
    client = openai.OpenAI(api_key=OPENAI_API_KEY)

# Logging
logging.basicConfig(
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s", level=logging.INFO
)

STATE_FILE = "state.json"
API_BASE = "https://draw.ar-lottery01.com/WinGo/WinGo_30S"
API_PATH = "GetHistoryIssuePage.json"  # dynamic timestamp param added when requesting


# Utilities: state persistence
def load_state():
    default = {
        "history": {
            "big_small": {"win": 0, "loss": 0},
            "color": {"win": 0, "loss": 0},
            "number": {"win": 0, "loss": 0},
        },
        "round_checked": None,  # last issue number we've seen
        "last_prediction": None,  # {predicted_issue, predicted_number, predicted_color, predicted_size, status}
    }
    try:
        if os.path.exists(STATE_FILE):
            with open(STATE_FILE, "r", encoding="utf-8") as f:
                data = json.load(f)
            # ensure keys present
            for k in default:
                if k not in data:
                    data[k] = default[k]
            return data
    except Exception:
        pass
    return default


def save_state(state):
    try:
        with open(STATE_FILE, "w", encoding="utf-8") as f:
            json.dump(state, f, ensure_ascii=False, indent=2)
    except Exception:
        logging.exception("Failed to save state")


# Mapping helpers
def num_to_color_map(n: int) -> str:
    # Based on your mapping: 1,3,5,7,9 = GREEN; 2,4,6,8 = RED; 0,5 = VIOLET (5 mixes too)
    if n == 0:
        return "RED & VIOLET"
    if n == 5:
        return "GREEN & VIOLET"
    if n in {1, 3, 7, 9}:
        return "GREEN"
    if n in {2, 4, 6, 8}:
        return "RED"
    # fallback
    return "UNKNOWN"


def num_to_size(n: int) -> str:
    return "BIG" if n >= 5 else "SMALL"


# Fetch latest results from API (runs in thread to avoid blocking)
async def fetch_latest_api():
    ts = int(time.time() * 1000)
    url = f"{API_BASE}/{API_PATH}?ts={ts}"
    headers = {
        "Accept": "application/json, text/plain, */*",
        "Referer": "https://dkwin9.com/",
        "Origin": "https://dkwin9.com",
        "User-Agent": "Mozilla/5.0 (compatible)",
    }
    try:
        # run requests.get in thread
        resp = await asyncio.to_thread(requests.get, url, {"timeout": 10, "headers": headers})
        # Note: requests.get signature when used via to_thread passes dict to second arg,
        # so better call as lambda for clarity:
    except Exception:
        # fallback correct call
        try:
            resp = await asyncio.to_thread(lambda: requests.get(url, timeout=10, headers=headers))
        except Exception as e:
            raise e

    if resp.status_code != 200:
        raise RuntimeError(f"API returned status {resp.status_code}")
    data = resp.json()
    return data


# Command handlers
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    text = (
        "ğŸ‘‹ à¦¸à§à¦¬à¦¾à¦—à¦¤à¦® â€” Premium Signal Bot\n\n"
        "à¦•à¦®à¦¾à¦¨à§à¦¡à¦¸à¦®à§‚à¦¹:\n"
        "/signal â€” à¦°à¦¿à§Ÿà§‡à¦² à¦¸à¦¿à¦—à¦¨à§à¦¯à¦¾à¦² (API à¦¬à§‡à¦¸à¦¡; à¦ªà¦°à¦¬à¦°à§à¦¤à§€ à¦°à¦¾à¦‰à¦¨à§à¦¡à§‡à¦° à¦œà¦¨à§à¦¯ à¦ªà§à¦°à§‡à¦¡à¦¿à¦•à¦¶à¦¨)\n"
        "/live â€” à¦Ÿà¦ª à¦²à§‡à¦Ÿà§‡à¦¸à§à¦Ÿ à¦°à§‡à¦œà¦¾à¦²à§à¦Ÿ (API à¦¥à§‡à¦•à§‡)\n"
        "/history â€” Win/Loss à¦¸à¦¾à¦°à¦¾à¦‚à¦¶\n"
        "/help â€” à¦¨à¦¿à¦°à§à¦¦à§‡à¦¶ à¦¦à§‡à¦–à¦¾à¦¬à§‡\n\n"
        "à¦¨à§‹à¦Ÿ: à¦¸à§‡à¦Ÿà¦†à¦ªà§‡à¦° à¦¸à¦®à§Ÿ BOT_TOKEN à¦“ (à¦à¦šà§à¦›à¦¿à¦•) Premium_Signal (OpenAI) env à¦¸à§‡à¦Ÿ à¦•à¦°à§‹à¥¤"
    )
    await update.message.reply_text(text)


async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await start(update, context)


# /live shows latest and evaluates pending prediction if new round arrived
async def live(update: Update, context: ContextTypes.DEFAULT_TYPE):
    state = load_state()
    try:
        data = await fetch_latest_api()
    except Exception as e:
        await update.message.reply_text(f"âš ï¸ à¦²à¦¾à¦‡à¦­ à¦¡à§‡à¦Ÿà¦¾ à¦†à¦¨à¦¤à§‡ à¦¸à¦®à¦¸à§à¦¯à¦¾: {e}")
        return

    # extract latest
    try:
        latest = data.get("data", {}).get("list", [])[0]
    except Exception:
        await update.message.reply_text("âš ï¸ API Response unexpected format.")
        return

    issue = latest.get("issueNumber")
    number_raw = latest.get("number")
    try:
        number = int(number_raw)
    except Exception:
        # sometimes number might be string with commas; try int conversion safe way
        try:
            number = int(str(number_raw).strip())
        except Exception:
            await update.message.reply_text("âš ï¸ à¦¨à¦®à§à¦¬à¦° à¦ªà¦¾à¦°à§à¦¸ à¦•à¦°à¦¤à§‡ à¦¸à¦®à¦¸à§à¦¯à¦¾à¥¤")
            return

    api_color = str(latest.get("color", "")).upper()
    size = num_to_size(number)
    our_color_from_num = num_to_color_map(number)

    # Evaluate pending prediction if we haven't checked this issue yet
    last_checked = state.get("round_checked")
    last_pred = state.get("last_prediction")

    eval_msg = ""
    if last_checked is None or str(last_checked) != str(issue):
        # new round arrived => evaluate previous pending prediction (if any)
        if last_pred and last_pred.get("status") == "pending":
            predicted_number = int(last_pred.get("predicted_number"))
            predicted_color = last_pred.get("predicted_color", "").upper()
            predicted_size = last_pred.get("predicted_size", "").upper()

            # Determine wins/losses
            number_win = predicted_number == number
            color_win = (predicted_color in api_color) or (predicted_color == our_color_from_num.upper())
            size_win = predicted_size == size

            # update history counters
            if number_win:
                state["history"]["number"]["win"] += 1
            else:
                state["history"]["number"]["loss"] += 1

            if color_win:
                state["history"]["color"]["win"] += 1
            else:
                state["history"]["color"]["loss"] += 1

            if size_win:
                state["history"]["big_small"]["win"] += 1
            else:
                state["history"]["big_small"]["loss"] += 1

            # mark prediction resolved
            last_pred["status"] = "won" if (number_win and color_win and size_win) else "lost"
            last_pred["resolved_with"] = {
                "issue": issue,
                "actual_number": number,
                "actual_color": api_color,
                "actual_size": size,
                "number_win": number_win,
                "color_win": color_win,
                "size_win": size_win,
                "resolved_at": int(time.time() * 1000),
            }
            state["last_prediction"] = last_pred
            eval_msg = (
                f"ğŸ”” à¦ªà§‚à¦°à§à¦¬à¦¬à¦°à§à¦¤à§€ à¦ªà§à¦°à§‡à¦¡à¦¿à¦•à¦¶à¦¨ à¦°à§‡à¦œà¦²à§à¦Ÿ à¦¹à§Ÿà§‡à¦›à§‡: {last_pred['status'].upper()}\n"
                f"â¡ï¸ Predicted #{last_pred['predicted_number']} ({last_pred['predicted_color']}, {last_pred['predicted_size']})\n"
                f"âœ”ï¸ Actual #{number} ({api_color}, {size})\n"
            )
        # update last checked
        state["round_checked"] = issue
        save_state(state)

    # Compose reply showing latest result
    reply = (
        f"ğŸ“¡ Live Result\n"
        f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
        f"ğŸ†” Issue: {issue}\n"
        f"ğŸ”¢ Number: {number}\n"
        f"ğŸ¨ API Color: {api_color}\n"
        f"ğŸ“ Size: {size}\n"
    )
    if eval_msg:
        reply = eval_msg + "\n" + reply

    await update.message.reply_text(reply)


# /signal uses latest API result to create a deterministic prediction for the next round
async def signal(update: Update, context: ContextTypes.DEFAULT_TYPE):
    state = load_state()
    try:
        data = await fetch_latest_api()
    except Exception as e:
        await update.message.reply_text(f"âš ï¸ à¦²à¦¾à¦‡à¦­ à¦¡à§‡à¦Ÿà¦¾ à¦†à¦¨à¦¤à§‡ à¦¸à¦®à¦¸à§à¦¯à¦¾: {e}")
        return

    try:
        latest = data.get("data", {}).get("list", [])[0]
    except Exception:
        await update.message.reply_text("âš ï¸ API Response unexpected format.")
        return

    issue = latest.get("issueNumber")
    number_raw = latest.get("number")
    try:
        last_number = int(number_raw)
    except Exception:
        try:
            last_number = int(str(number_raw).strip())
        except Exception:
            await update.message.reply_text("âš ï¸ à¦¨à¦®à§à¦¬à¦° à¦ªà¦¾à¦°à§à¦¸ à¦•à¦°à¦¤à§‡ à¦¸à¦®à¦¸à§à¦¯à¦¾à¥¤")
            return

    # Deterministic prediction logic (simple, repeatable): next_number = (last_number + 1) % 10
    predicted_number = (last_number + 1) % 10
    predicted_size = num_to_size(predicted_number)
    predicted_color = num_to_color_map(predicted_number)

    # Next issue guess (try incrementing numeric issueNumber if possible)
    predicted_issue = None
    try:
        predicted_issue = str(int(issue) + 1)
    except Exception:
        predicted_issue = f"{issue}_next"

    # store prediction as pending
    new_pred = {
        "predicted_issue": predicted_issue,
        "predicted_number": predicted_number,
        "predicted_color": predicted_color,
        "predicted_size": predicted_size,
        "timestamp": int(time.time() * 1000),
        "status": "pending",
    }
    state["last_prediction"] = new_pred
    save_state(state)

    reply = (
        f"ğŸ¯ Signal (Predicted for next issue)\n"
        f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
        f"ğŸ” Based on last Issue: {issue} â†’ last number {last_number}\n"
        f"ğŸ†” Predicted Issue: {predicted_issue}\n"
        f"ğŸ”¢ Predicted Number: {predicted_number}\n"
        f"ğŸ¨ Predicted Color: {predicted_color}\n"
        f"ğŸ“ Predicted Size: {predicted_size}\n\n"
        f"âš ï¸ Prediction saved. Use /live later to get actual result and evaluation."
    )
    await update.message.reply_text(reply)


# /history prints the saved win/loss counters and last prediction details
async def history_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    state = load_state()
    h = state.get("history", {})
    last_pred = state.get("last_prediction")
    reply = (
        f"ğŸ“Š Signal History Summary\n"
        f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
        f"BIG/SMALL â†’ âœ… {h['big_small']['win']} | âŒ {h['big_small']['loss']}\n"
        f"COLOR     â†’ âœ… {h['color']['win']} | âŒ {h['color']['loss']}\n"
        f"NUMBER    â†’ âœ… {h['number']['win']} | âŒ {h['number']['loss']}\n\n"
    )
    if last_pred:
        reply += (
            "ğŸ“Œ Last Prediction:\n"
            f"  Issue: {last_pred.get('predicted_issue')}\n"
            f"  Number: {last_pred.get('predicted_number')}\n"
            f"  Color: {last_pred.get('predicted_color')}\n"
            f"  Size: {last_pred.get('predicted_size')}\n"
            f"  Status: {last_pred.get('status')}\n"
        )
        if last_pred.get("status") in ("won", "lost") and last_pred.get("resolved_with"):
            r = last_pred["resolved_with"]
            reply += (
                f"  Resolved Issue: {r.get('issue')}\n"
                f"  Actual Number: {r.get('actual_number')}\n"
                f"  Wins: number={r.get('number_win')}, color={r.get('color_win')}, size={r.get('size_win')}\n"
            )
    await update.message.reply_text(reply)


# ChatGPT handler (uses new OpenAI SDK if available, otherwise replies fallback)
async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if client is None:
        await update.message.reply_text("âš ï¸ OpenAI API key missing â€” Chat replies not available.")
        return
    user_message = update.message.text
    try:
        resp = await asyncio.to_thread(
            lambda: client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": user_message}],
            )
        )
        reply = resp.choices[0].message.content
        await update.message.reply_text(reply)
    except Exception as e:
        await update.message.reply_text(f"âš ï¸ OpenAI error: {e}")


# Main
def main():
    if not BOT_TOKEN:
        logging.error("BOT_TOKEN environment variable not set. Exiting.")
        return

    app = ApplicationBuilder().token(BOT_TOKEN).build()

    app.add_handler(CommandHandler("start", start))
    app.add_handler(CommandHandler("help", help_command))
    app.add_handler(CommandHandler("live", live))
    app.add_handler(CommandHandler("signal", signal))
    app.add_handler(CommandHandler("history", history_command))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))

    logging.info("Bot starting...")
    app.run_polling()


if __name__ == "__main__":
    main()
```î¨0î¨‚
